{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aliens\n",
    "The title of the notebook should be coherent with file name. Namely, file name should be:    \n",
    "*author's initials_progressive number_title.ipynb*    \n",
    "For example:    \n",
    "*EF_01_Data Exploration.ipynb*\n",
    "\n",
    "## Purpose\n",
    "State the purpose of the notebook.\n",
    "\n",
    "## Methodology\n",
    "Quickly describe assumptions and processing steps.\n",
    "\n",
    "## WIP - improvements\n",
    "Use this section only if the notebook is not final.\n",
    "\n",
    "Notable TODOs:\n",
    "- todo 1;\n",
    "- todo 2;\n",
    "- todo 3.\n",
    "\n",
    "## Results\n",
    "Describe and comment the most important results.\n",
    "\n",
    "## Suggested next steps\n",
    "State suggested next steps, based on results obtained in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Using cached geopandas-0.7.0-py2.py3-none-any.whl (928 kB)\n",
      "Collecting shapely\n",
      "  Using cached Shapely-1.7.0-cp37-cp37m-win_amd64.whl (1.0 MB)\n",
      "Collecting pyproj>=2.2.0\n",
      "  Downloading pyproj-2.5.0-cp37-cp37m-win_amd64.whl (24.0 MB)\n",
      "Collecting fiona\n",
      "  Using cached Fiona-1.8.13.post1.tar.gz (1.2 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'c:\\programdata\\anaconda3\\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\seank\\\\AppData\\\\Local\\\\Temp\\\\pip-install-l8p3bzo7\\\\fiona\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\seank\\\\AppData\\\\Local\\\\Temp\\\\pip-install-l8p3bzo7\\\\fiona\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\seank\\AppData\\Local\\Temp\\pip-install-l8p3bzo7\\fiona\\pip-egg-info'\n",
      "         cwd: C:\\Users\\seank\\AppData\\Local\\Temp\\pip-install-l8p3bzo7\\fiona\\\n",
      "    Complete output (1 lines):\n",
      "    A GDAL API version must be specified. Provide a path to gdal-config using a GDAL_CONFIG environment variable or use a GDAL_VERSION environment variable.\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "#!pip install splinter\n",
    "#!pip install geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import\n",
    "We import all the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-654b5c25f8c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from sqlalchemy import create_engine\n",
    "from shapely.geometry import Point, Polygon\n",
    "from citipy import citipy\n",
    "\n",
    "# Google API Key\n",
    "from config import gkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local library import\n",
    "We import all the required local libraries libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Chromedriver path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set executable path and initialize Chrome Browser\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin scrape code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit \n",
    "ufo_url = 'http://www.nuforc.org/webreports/ndxevent.html'\n",
    "browser.visit(ufo_url)\n",
    "\n",
    "# add in a pause to allow site to fully load before creating html object\n",
    "time.sleep(3)\n",
    "\n",
    "# create html object\n",
    "html = browser.html\n",
    "\n",
    "# create a beautiful soup object\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "# create list to house the table urls\n",
    "table_urls = []\n",
    "base_url = 'http://www.nuforc.org/webreports/'\n",
    "    \n",
    "# retrieve all urls\n",
    "links = soup.find_all('a')[1:13]\n",
    "\n",
    "# for loop to loop through items and append to list\n",
    "for link in links:\n",
    "     part_url = link['href']\n",
    "     full_url = base_url + part_url   \n",
    "     table_urls.append(full_url)\n",
    "        \n",
    "\n",
    "print(table_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list\n",
    "table_list = []\n",
    "\n",
    "# loop through list to scrape table data and extend, rather than append to empty list\n",
    "for table in table_urls:\n",
    "    urls = pd.read_html(table)\n",
    "    table_list.extend(urls)\n",
    "    \n",
    "\n",
    "print(table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concatenate all table data into one dataframe\n",
    "pd.concat(table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(table_list).to_csv(\"Resources/nuforc_reports.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"Resources/nuforc_reports.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at what we are starting with\n",
    "for col in df.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "print(df2.count())\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "df3 = df2.copy()\n",
    "\n",
    "df3.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "print(df3.count())\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#only US States\n",
    "aliens_df = df3[\\\n",
    "(df3['State']=='AL')|(df3['State']=='AK')|(df3['State']=='AZ')\\\n",
    "|(df3['State']=='AR')|(df3['State']=='CA')|(df3['State']=='CO')\\\n",
    "|(df3['State']=='CT')|(df3['State']=='DE')|(df3['State']=='FL')\\\n",
    "|(df3['State']=='GA')|(df3['State']=='HI')|(df3['State']=='ID')\\\n",
    "|(df3['State']=='IL')|(df3['State']=='IN')|(df3['State']=='IA')\\\n",
    "|(df3['State']=='KS')|(df3['State']=='KY')|(df3['State']=='LA')\\\n",
    "|(df3['State']=='ME')|(df3['State']=='MD')|(df3['State']=='MA')\\\n",
    "|(df3['State']=='MI')|(df3['State']=='MN')|(df3['State']=='MS')\\\n",
    "|(df3['State']=='MO')|(df3['State']=='MT')|(df3['State']=='NE')\\\n",
    "|(df3['State']=='NV')|(df3['State']=='NH')|(df3['State']=='NJ')\\\n",
    "|(df3['State']=='NM')|(df3['State']=='NY')|(df3['State']=='NC')\\\n",
    "|(df3['State']=='ND')|(df3['State']=='OH')|(df3['State']=='OK')\\\n",
    "|(df3['State']=='OR')|(df3['State']=='PA')|(df3['State']=='RI')\\\n",
    "|(df3['State']=='SC')|(df3['State']=='SD')|(df3['State']=='TN')\\\n",
    "|(df3['State']=='TX')|(df3['State']=='UT')|(df3['State']=='VT')\\\n",
    "|(df3['State']=='VA')|(df3['State']=='WA')|(df3['State']=='WV')\\\n",
    "|(df3['State']=='WI')|(df3['State']=='WY')]\n",
    "aliens_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliens_df.to_csv(\"Resources/clean_aliens.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Lat/Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import aliens file as DataFrame\n",
    "aliens_pd = pd.read_csv(\"Resources/clean_aliens.csv\")\n",
    "aliens_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for lat, lng, airport name, airport address, airport rating\n",
    "# Note that we used \"\" to specify initial entry.\n",
    "aliens_pd[\"Lat\"] = \"\"\n",
    "aliens_pd[\"Lng\"] = \"\"\n",
    "aliens_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of alieins_pd\n",
    "aliens_pd_mod = aliens_pd.copy()\n",
    "\n",
    "# create a params dict that will be updated with new city each iteration\n",
    "params = {\"key\": gkey}\n",
    "\n",
    "# Loop through the cities_pd and run a lat/long search for each city\n",
    "for index, row in aliens_pd_mod.iterrows():\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "\n",
    "    city = row['City']\n",
    "    state = row['State']\n",
    "\n",
    "    # update address key value\n",
    "    params['address'] = f\"{city},{state}\"\n",
    "\n",
    "    # make request\n",
    "    aliens_lat_lng = requests.get(base_url, params=params)\n",
    "    \n",
    "    # print the cities_lat_lng url, avoid doing for public github repos in order to avoid exposing key\n",
    "    # print(cities_lat_lng.url)\n",
    "    \n",
    "    # convert to json\n",
    "    aliens_lat_lng = aliens_lat_lng.json()\n",
    "\n",
    "    aliens_pd_mod.loc[index, \"Lat\"] = aliens_lat_lng[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
    "    aliens_pd_mod.loc[index, \"Lng\"] = aliens_lat_lng[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n",
    "\n",
    "# Visualize to confirm lat lng appear\n",
    "aliens_pd_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Nuclear Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_nuclear_power_stations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = requests.get(url)\n",
    "# c = r.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_html(url,encoding='utf-8')\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Station', 'Units', 'Capacity_MWe', 'Country', \n",
    "              'Location', 'Refs']\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = df[\"Location\"].str.split(\" / \", n = 1, expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DMS_Lat_Long\"]= coordinates[0] \n",
    "df[\"GP_Lat_Long\"]= coordinates[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping old Location and Refs columns \n",
    "df.drop(columns =[\"Location\",\"Refs\",\"DMS_Lat_Long\"], inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DMS_coordinates = df[\"GP_Lat_Long\"].str.split(\" \", n = 1, expand = True)\n",
    "df[\"GP_Lat\"]= DMS_coordinates[0] \n",
    "df[\"GP_Long\"]= DMS_coordinates[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dms2dd(s):\n",
    "    # example: s = \"\"\"0°51'56.29\"S\"\"\"\n",
    "    coord, direction = re.split('°', s)\n",
    "    #dd = float(degrees) + float(minutes)/60 + float(seconds)/(60*60);\n",
    "    coord = coord.replace(u'\\ufeff','')\n",
    "    coord = float(coord)\n",
    "    if direction in ('S','W'):\n",
    "        coord*= -1\n",
    "    return coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Latitude'] = df['GP_Lat'].apply(dms2dd)\n",
    "df['Longitude'] = df['GP_Long'].apply(dms2dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns =[\"GP_Lat_Long\",\"GP_Lat\",\"GP_Long\"], inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = df[df[\"Country\"] == \"United States\"]\n",
    "type(us['Latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#us['City'] = citipy.nearest_city(us['Latitude'].astype(float), us['Longitude'].astype(float)).city_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(\n",
    "    us, geometry=geopandas.points_from_xy(us.Longitude, us.Latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# We restrict to North America.\n",
    "ax = world[world.name == \"United States of America\"].plot(\n",
    "    color='white', edgecolor='black', figsize=(18,10))\n",
    "\n",
    "# We can now plot our ``GeoDataFrame``.\n",
    "gdf.plot(ax=ax, color='red',edgecolors='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
